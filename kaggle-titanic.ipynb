{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic death predicion using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e5438598-e49c-44bf-b328-0af7ffaf8ee1",
    "_uuid": "a5360842311c97facc08a113208b75a9fc8a72ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b7b58824-9e76-474a-b31c-b80514c57b07",
    "_uuid": "93f6f85a09ffdd943e1abb095c26e22f3241ab84",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Baseline models\n",
    "\n",
    "baseline = {\"tautis\": 0.76, \"always no\": 0.616}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "49508e62-3fa5-4936-99a4-d9df82569636",
    "_uuid": "327c7771127b3b90c4de75d44a96d3d6ae75c69c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from kaggle\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local testing \n",
    "\n",
    "full_dataset = pd.read_csv(\"../input/titanic.csv\")\n",
    "\n",
    "## make format similar to kaggle\n",
    "full_dataset.drop(['boat','body', 'home.dest'], axis=1, inplace=True)\n",
    "full_dataset.rename(columns={\n",
    "    'pclass': 'Pclass', 'survived': 'Survived', \"name\": \"Name\", \"sex\":\"Sex\",\n",
    "    \"age\":\"Age\", \"sibsp\":\"SibSp\", \"parch\":\"Parch\", \"ticket\": \"Ticket\",\n",
    "    \"fare\":\"Fare\", \"cabin\":\"Cabin\", \"embarked\":\"Embarked\"\n",
    "}, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test, _, _ = train_test_split(full_dataset, full_dataset, test_size=0.32, random_state=0)\n",
    "\n",
    "def localTest(prediction):\n",
    "    \"localy test prediction accuracy on test score\"\n",
    "    assert(len(prediction) == len(test))\n",
    "    return (test.Survived == prediction).sum() / len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "03ef552a-e038-4649-8ead-42506fb70f60",
    "_uuid": "d6500286ec99e793e5379ac90499863268f93c5e"
   },
   "source": [
    "# Plan \n",
    " 1. Understand data\n",
    " 2. Split the data - I think this is already done for me \n",
    " 3. Feature engineer \n",
    " 4. Data generator\n",
    " 5. Run few decision tree models. I want to try decision trees, random trees, boosted methods. All must run on the same data. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "341a22de-6745-4ef2-ae57-7341b095e7a1",
    "_uuid": "2c7984b3f723b785069df7939670d9f23f7fea28",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c303c29-36d4-403c-9ccf-dfa426a1a894",
    "_uuid": "7c523706b2e47808b65b0e71382896bbb6479c27",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "38cf7df9-2194-4c3e-942f-60231cf980f6",
    "_uuid": "082ec2ab181d41aade2f0f1befea46c460b1cba7"
   },
   "source": [
    "## Observations:\n",
    " 1. Break up into separate vectors `Pclass` ,`Embarked`\n",
    " 2. Drop `Name` , `PassengerId`, `Survived`, `Ticket`\n",
    " 3. Split `Cabin` into a letter vectors and a number\n",
    " 4. Binarize `Sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "8be76d71-e9bb-4580-89c5-d0fc4eaa9048",
    "_uuid": "76149dcfeccd7104d8abe94c10c6840d4bce668d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def breakupIntoVectors(row, prefix):\n",
    "    \"\"\"\n",
    "    creates separate classes for predictor\n",
    "    if nan, propagate nan\n",
    "    \"\"\"\n",
    "    unique = row.unique()\n",
    "    mask = unique == unique\n",
    "    unique = unique[mask]\n",
    "    new_df = {}\n",
    "    for key in unique:\n",
    "        new_df[prefix + str(key)] = row == key\n",
    "        new_df[prefix + str(key)][row.isnull()] = np.nan\n",
    "    \n",
    "    return pd.DataFrame(new_df)\n",
    "        \n",
    "\n",
    "def binarizeSex(df):\n",
    "    \"male = 1, female = 0\"\n",
    "    row = df.Sex\n",
    "    res = row == \"male\"\n",
    "    res[row.isnull()] = np.nan\n",
    "    return pd.DataFrame( {\"Sex\": res})\n",
    "\n",
    "def splitCabin(df):\n",
    "    \"break up cabin into letter and number\"\n",
    "    row = df.Cabin\n",
    "    # to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "93282cdc-1efa-4c2e-b04e-b14545de6faa",
    "_uuid": "a831ff70b00866667be534cc4db248aa3b8bfa3e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareDataset(df):\n",
    "    \"prepare structure\"\n",
    "    df_pclass = breakupIntoVectors(df.Pclass, \"Pclass_\")\n",
    "    df_Embarked = breakupIntoVectors(df.Embarked, \"Embarked_\")\n",
    "    df_sex = binarizeSex(df)\n",
    "    df_others = pd.DataFrame({\n",
    "        \"Age\" : df.Age,\n",
    "        \"SibSp\" : df.SibSp,\n",
    "        \"Parch\" : df.Parch,\n",
    "        \"Fare\" : df.Fare,\n",
    "        \"FareLog\" : np.log(df.Fare+1)\n",
    "    })\n",
    "    return pd.concat([df_pclass, df_Embarked, df_sex, df_others], axis=1)\n",
    "\n",
    "import random\n",
    "\n",
    "def randomiseMissingData(df2):\n",
    "    \"randomise missing data on pandas\"\n",
    "    df = df2.copy()\n",
    "    for col in df.columns:\n",
    "        data = df[col]\n",
    "        mask = data.isnull()\n",
    "        samples = random.choices( data[~mask].values , k = mask.sum() )\n",
    "        data[mask] = samples\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prepareLabels(df):\n",
    "    \"prepare labels\"\n",
    "    return df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "c7b6e1d4-8678-42ac-a367-959940c4157e",
    "_uuid": "03461279312a9ea0e57ceb7e67744c8ffe4b12a6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveSubmisionFile(prediction, filename):\n",
    "    \"saves submission output, assuming that predictions come in the same sequence and test df\"\n",
    "    assert(len(prediction) == len(test))\n",
    "    out = pd.DataFrame({\n",
    "        \"PassengerId\" : test.PassengerId.values,\n",
    "        \"Survived\" : prediction.astype(int)\n",
    "    })\n",
    "    print(\"save file: \"+ filename+ \" with shape:\",out.shape)\n",
    "    out.to_csv( filename , index = False )\n",
    "    \n",
    "def runPredictionsFor(n):\n",
    "    \"run predictions for n times\"\n",
    "    res = [ predict() for i in range(n)]\n",
    "    return np.apply_along_axis( func1d=np.median, arr=np.vstack(res), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9bb3a2fd-4774-4daf-a518-110b3607d7e3",
    "_uuid": "1a10387c2456df28f50c7703775c75cc85a1d587"
   },
   "source": [
    "Due to random filling of missing data, we must run our algorithms multiple times to get an unbiased prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "f47f7160-65db-4e9a-a422-8adc8168c6fc",
    "_uuid": "5d71f3ed7527c6d5b48656e7cf4685f1dc7e57c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmisiunas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_tree_runs_1 0.744630071599\n",
      "simple_tree_runs_100 0.770883054893\n"
     ]
    }
   ],
   "source": [
    "# simple decision tree\n",
    "\n",
    "def predict(): \n",
    "    from sklearn import tree\n",
    "    global clf\n",
    "    \n",
    "    X = randomiseMissingData(prepareDataset(train))\n",
    "    Y = prepareLabels(train)\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X, Y)\n",
    "\n",
    "    X_test = randomiseMissingData(prepareDataset(test))\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "out1 = runPredictionsFor(1)\n",
    "print(\"simple_tree_runs_1\", localTest(out1)) # 0.7446\n",
    "\n",
    "#saveSubmisionFile(out1, \"simple_tree_runs_1.csv\")\n",
    "# results on kaggle test set: 0.70813\n",
    "\n",
    "out100 = runPredictionsFor(100)\n",
    "print(\"simple_tree_runs_100\", localTest(out100)) # 0.7708\n",
    "\n",
    "#saveSubmisionFile(out100, \"simple_tree_runs_100.csv\")\n",
    "# results on kaggle test set: 0.72727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass_1', 0.014338316687684654),\n",
       " ('Pclass_2', 0.003733659993623413),\n",
       " ('Pclass_3', 0.080565638777347265),\n",
       " ('Embarked_C', 0.0095446947205410602),\n",
       " ('Embarked_Q', 0.0066884285073721978),\n",
       " ('Embarked_S', 0.01560213383185452),\n",
       " ('Sex', 0.29547726937755259),\n",
       " ('Age', 0.2389043399029615),\n",
       " ('Fare', 0.10058526805468999),\n",
       " ('FareLog', 0.15702541894907676),\n",
       " ('Parch', 0.03718173997722965),\n",
       " ('SibSp', 0.04035309122006648)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X.keys(),clf.feature_importances_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "acfb07af-ef98-4a1b-b31e-3c9e236fd963",
    "_uuid": "42c5b578290018edf602332cbc625cb6ae438d19",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random forrests \n",
    "def predict(): \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    global clf, X, Y\n",
    "    \n",
    "    X = randomiseMissingData(prepareDataset(train))\n",
    "    Y = prepareLabels(train)\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf = clf.fit(X, Y)\n",
    "\n",
    "    X_test = randomiseMissingData(prepareDataset(test))\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "\n",
    "out1 = runPredictionsFor(1)\n",
    "print(\"random_forests_1_runs_1\", localTest(out1)) # 0.735\n",
    "\n",
    "#saveSubmisionFile(out1, \"random_forests_1_runs_1.csv\")\n",
    "# results on kaggle test set: 0.72248\n",
    "\n",
    "out100 = runPredictionsFor(100)\n",
    "print(\"random_forests_1_runs_100\", localTest(out100)) # 0.735\n",
    "\n",
    "#saveSubmisionFile(out100, \"random_forests_1_runs_100.csv\")\n",
    "# results on kaggle test set: 0.72248"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a surprising result is that `out1 == out100` for random forests. This was not the case for the decision tree. There might be a bug somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "11e4c0d5-b98b-44ab-b9d0-09f85d54024d",
    "_uuid": "c615586a63dd47c5f24cf79bcbd04e161632542a",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass_1', 0.15325717017649079),\n",
       " ('Pclass_2', 0.0),\n",
       " ('Pclass_3', 0.12796425192666278),\n",
       " ('Embarked_C', 0.017696833313819126),\n",
       " ('Embarked_Q', 0.0017106614995323506),\n",
       " ('Embarked_S', 0.010501231225105389),\n",
       " ('Sex', 0.33586081249295024),\n",
       " ('Age', 0.011438564695887051),\n",
       " ('Fare', 0.095696470835129402),\n",
       " ('FareLog', 0.19202316241156819),\n",
       " ('Parch', 0.053850841422854664),\n",
       " ('SibSp', 0.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X.keys(),clf.feature_importances_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c18f7aa-62d1-4720-a166-bc80029e4cb2",
    "_uuid": "0768372c98666afcde8cab22f529949389351fbd"
   },
   "outputs": [],
   "source": [
    "# xgBoost\n",
    "def predict(): \n",
    "    from xgboost import XGBClassifier\n",
    "    global clf, X, Y\n",
    "\n",
    "    X = randomiseMissingData(prepareDataset(train))\n",
    "    Y = prepareLabels(train) \n",
    "\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(X, Y)\n",
    "    \n",
    "    X_test = randomiseMissingData(prepareDataset(test))\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "out1 = runPredictionsFor(1)\n",
    "print(\"xgboost_1_runs_1\", localTest(out1)) # 0.8019093\n",
    "\n",
    "#saveSubmisionFile(out1, \"xgboost_1_runs_1.csv\")\n",
    "# results on kaggle test set: 0.77511\n",
    "\n",
    "out100 = runPredictionsFor(100)\n",
    "print(\"xgboost_1_runs_100\", localTest(out100)) # 0.80190\n",
    "\n",
    "#saveSubmisionFile(out100, \"xgboost_1_runs_100.csv\")\n",
    "# results on kaggle test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pclass_1', 0.17219018794097454),\n",
       " ('Pclass_2', 0.0),\n",
       " ('Pclass_3', 0.14872151114990478),\n",
       " ('Embarked_C', 0.0026618471101808815),\n",
       " ('Embarked_Q', 0.0),\n",
       " ('Embarked_S', 0.0),\n",
       " ('Sex', 0.35740188103811665),\n",
       " ('Age', 0.010275356821308495),\n",
       " ('Fare', 0.090821787175992791),\n",
       " ('FareLog', 0.15914369578151835),\n",
       " ('Parch', 0.058783732982003456),\n",
       " ('SibSp', 0.0)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf)\n",
    "list(zip(X.keys(),clf.feature_importances_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "If accuracy was the aim, we could make better use of the data:\n",
    " - use name as a proxy for class\n",
    " - use cabin position as a atribute (see above)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
